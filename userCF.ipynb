{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_items(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    items = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        item_id, attribute_1, attribute_2 = line.split('|')\n",
    "        item_id = int(item_id)\n",
    "        if attribute_1 == 'None':\n",
    "            attribute_1 = None\n",
    "        if attribute_2 == 'None':\n",
    "            attribute_2 = None\n",
    "        items[item_id] = (attribute_1, attribute_2)\n",
    "\n",
    "    return items\n",
    "\n",
    "items = load_items('./data/itemAttribute.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rating data\n",
    "data_path = './data/train.txt'\n",
    "train_lines = 0\n",
    "all_avg = 0\n",
    "item_rating= {}\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    user_id = None\n",
    "    train_lines = len(lines)\n",
    "    data = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if '|' in line:  # user line\n",
    "            train_lines -= 1\n",
    "            if(user_id != None):\n",
    "                avg = data[user_id]['sum'] / data[user_id]['num_ratings']\n",
    "                data[user_id]['ratings'].update({k: v - avg for k, v in data[user_id]['ratings'].items()})\n",
    "                data[user_id]['norm'] = sum(x**2 for x in data[user_id]['ratings'].values())**0.5\n",
    "\n",
    "            user_id, num_ratings = line.split('|')\n",
    "            user_id = int(user_id)\n",
    "            data[user_id] = {}\n",
    "            data[user_id]['num_ratings'] = int(num_ratings)\n",
    "            data[user_id]['ratings'] = {}\n",
    "            data[user_id]['sum'] = 0\n",
    "        else:  # rating line\n",
    "            item_id, score = map(int, line.split())\n",
    "            data[user_id]['ratings'][item_id] = score\n",
    "            data[user_id]['sum'] += score\n",
    "            all_avg += score\n",
    "            if item_id not in item_rating:\n",
    "                item_rating[item_id] = {'num': 0, 'sum': 0}\n",
    "            item_rating[item_id]['num'] += 1\n",
    "            item_rating[item_id]['sum'] += score\n",
    "\n",
    "    avg = data[user_id]['sum'] / data[user_id]['num_ratings']\n",
    "    data[user_id]['ratings'].update({k: v - avg for k, v in data[user_id]['ratings'].items()})\n",
    "    data[user_id]['norm'] = sum(x**2 for x in data[user_id]['ratings'].values())**0.5\n",
    "\n",
    "all_avg /= train_lines\n",
    "lines = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19835/19835 [1:23:37<00:00,  3.95it/s]  \n"
     ]
    }
   ],
   "source": [
    "#cacluate similarity between users\n",
    "#takes 1 hour 20mins\n",
    "similarity = {}\n",
    "for i, (userid1, user1_data) in tqdm(enumerate(data.items()), total=len(data)):\n",
    "    similarity[userid1] = {}\n",
    "    for j, (userid2, user2_data) in enumerate(data.items()):\n",
    "        if  user1_data['norm'] == 0 or  user2_data['norm'] == 0:\n",
    "            similarity[userid1][userid2] = 0\n",
    "            continue\n",
    "        if i >= j:\n",
    "            continue\n",
    "        else:\n",
    "            cos_sim = 0.0\n",
    "            for item, rating in user1_data['ratings'].items():\n",
    "                if item in user2_data['ratings']:\n",
    "                    cos_sim += rating * user2_data['ratings'][item]\n",
    "            cos_sim = cos_sim / (user1_data['norm'] * user2_data['norm'])\n",
    "            similarity[userid1][userid2] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save similarity matrix\n",
    "np.save('similarity.npy', similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load similarity matrix\n",
    "similarity = np.load('similarity.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27493"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(similarity[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test data\n",
    "test_input = {}\n",
    "with open('./data/test.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()  # 去除行尾的换行符\n",
    "        if '|' in line:\n",
    "            # 这是一个用户的开始\n",
    "            userid, num_items = line.split('|')  # 分割用户ID和评分项目数量\n",
    "            test_input[userid] = {'num_items': int(num_items), 'items': []}\n",
    "        else:\n",
    "            # 这是一个项目ID\n",
    "            itemid = line\n",
    "            test_input[userid]['items'].append(itemid)\n",
    "lines = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def find_top_n_keys(dictionary, n):\n",
    "    top_n_items = heapq.nlargest(n, ((k, v) for k, v in dictionary.items()), key=lambda item: item[1])\n",
    "    top_n_keys = [key for (key, value) in top_n_items ]\n",
    "    return top_n_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19835/19835 [02:04<00:00, 159.60it/s]\n"
     ]
    }
   ],
   "source": [
    "test_output = {}\n",
    "\n",
    "for user_id, user_data in (tqdm(test_input.items())):\n",
    "    user_id = int(user_id)\n",
    "    test_output[user_id] = {}\n",
    "    N_neighbor = find_top_n_keys(similarity[user_id], 500)\n",
    "    for item_id in user_data['items']:\n",
    "        item_id = int(item_id)\n",
    "        eval = 0\n",
    "        sim_sum = 0\n",
    "        for neighbor in N_neighbor:\n",
    "            if item_id in data[neighbor]['ratings']:\n",
    "                sim_sum += similarity[user_id][neighbor]\n",
    "                baseline = data[neighbor]['sum']/data[neighbor]['num_ratings'] +  item_rating[item_id]['sum']/item_rating[item_id]['num'] - all_avg\n",
    "                eval += similarity[user_id][neighbor] * (data[neighbor]['ratings'][item_id] + data[neighbor]['sum']/data[neighbor]['num_ratings'] - baseline)\n",
    "        if sim_sum != 0:\n",
    "            eval /= sim_sum\n",
    "        if item_id in item_rating:\n",
    "            baseline = data[user_id]['sum']/data[user_id]['num_ratings'] +  item_rating[item_id]['sum']/item_rating[item_id]['num'] - all_avg\n",
    "        else:\n",
    "            baseline = data[user_id]['sum']/data[user_id]['num_ratings']\n",
    "        eval += baseline\n",
    "        if eval > 100:\n",
    "            eval = 100\n",
    "        test_output[user_id][item_id] = int(eval) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'result_baseline.txt'\n",
    "count = 0\n",
    "with open(result_path, 'w') as f:\n",
    "    for userid, item_list in test_output.items():\n",
    "        f.write(f\"{userid}|6\\n\")\n",
    "        for item, rating in item_list.items():\n",
    "            f.write(f\"{item}  {rating}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = {}\n",
    "for userid in data.keys():\n",
    "    bias[userid] = data[userid]['sum']/data[userid]['num_ratings'] - all_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {k:similarity[0][k] for k in find_top_n_keys(similarity[0], 20)}\n",
    "dic = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = {}\n",
    "lr = 0.2\n",
    "for userid in data.keys():\n",
    "    weight[userid] = {k:similarity[userid][k] for k in find_top_n_keys(similarity[userid], 100)}\n",
    "    for neighbor in weight[userid].keys():\n",
    "        grad = 0\n",
    "        for itemid in data[userid]['ratings'].keys():\n",
    "            if itemid in data[neighbor]['ratings']:\n",
    "                grad += weight[userid][neighbor] * (data[neighbor]['ratings'][itemid] + \\\n",
    "                                                      data[neighbor]['sum']/data[neighbor]['num_ratings'] - \\\n",
    "                                                      bias[neighbor] - item_rating[item_id]['sum']/item_rating[item_id]['num'])\n",
    "        if grad == 0: #没有共同评分的项目\n",
    "            continue\n",
    "        grad += bias[userid] + item_rating[item_id]['sum']/item_rating[item_id]['num']\n",
    "        \n",
    "\n",
    "    # for itemid in data[userid]['ratings'].keys():\n",
    "    #     eval = 0\n",
    "    #     for neighbor in weight[userid].keys():\n",
    "    #         if itemid in data[neighbor]['ratings']:\n",
    "    #             eval += weight[userid][neighbor] * (data[neighbor]['ratings'][itemid] + \\\n",
    "    #                                                  data[neighbor]['sum']/data[neighbor]['num_ratings'] - \\\n",
    "    #                                                  bias[neighbor] - item_rating[item_id]['sum']/item_rating[item_id]['num'])\n",
    "        \n",
    "    weight[userid][itemid] = data[userid]['ratings'][itemid] + bias[userid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19835/19835 [02:07<00:00, 155.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate done\n",
      "write done\n"
     ]
    }
   ],
   "source": [
    "#the oridinary version\n",
    "from tqdm import tqdm\n",
    "test_output = {}\n",
    "\n",
    "for user_id, user_data in (tqdm(test_input.items())):\n",
    "    user_id = int(user_id)\n",
    "    test_output[user_id] = {}\n",
    "    N_neighbor = find_top_n_keys(similarity[user_id], 500)\n",
    "    for item_id in user_data['items']:\n",
    "        item_id = int(item_id)\n",
    "        eval = 0\n",
    "        sim_sum = 0\n",
    "        for neighbor in N_neighbor:\n",
    "            if item_id in data[neighbor]['ratings']:\n",
    "                sim_sum += similarity[user_id][neighbor]\n",
    "                eval += similarity[user_id][neighbor] * (data[neighbor]['ratings'][item_id] + data[neighbor]['sum']/data[neighbor]['num_ratings'])\n",
    "        if sim_sum != 0:\n",
    "            eval /= sim_sum\n",
    "        test_output[user_id][item_id] = int(eval)\n",
    "            \n",
    "\n",
    "print('evaluate done')\n",
    "\n",
    "result_path = 'result_normal.txt'\n",
    "count = 0\n",
    "with open(result_path, 'w') as f:\n",
    "    for userid, item_list in test_output.items():\n",
    "        f.write(f\"{userid}|6\\n\")\n",
    "        for item, rating in item_list.items():\n",
    "            f.write(f\"{item}  {rating}\\n\")\n",
    "\n",
    "print('write done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sim_top_10.txt', 'w') as f:\n",
    "    for i, (userid1, user1_data) in enumerate(similarity.items()):\n",
    "        if(i<=10):\n",
    "            f.write(f\"{userid1}: \\n \")\n",
    "            for userid2, cos_sim in user1_data.items():\n",
    "                f.write(f\"{userid2} {cos_sim}\\n\")\n",
    "        else:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
